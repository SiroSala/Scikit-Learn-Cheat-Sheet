<div style="text-align: center;">
  <h1>ğŸš€ Becoming a Scikit-Learn Boss in 90 Days: Day 1 â€“ Introduction and Getting Started ğŸğŸ“š</h1>
  <p>Embark on Your Journey to Master Machine Learning with Scikit-Learn!</p>
</div>

---

## ğŸ“‘ Table of Contents

1. [ğŸŒŸ Welcome to Day 1](#welcome-to-day-1)
2. [ğŸ” What is Scikit-Learn?](#what-is-scikit-learn-ğŸ”)
3. [ğŸ› ï¸ Setting Up Your Environment](#setting-up-your-environment-ğŸ› ï¸)
    - [ğŸ“¦ Installing Scikit-Learn](#installing-scikit-learn-ğŸ“¦)
    - [ğŸ’» Setting Up a Virtual Environment](#setting-up-a-virtual-environment-ğŸ’»)
4. [ğŸ§© Understanding Scikit-Learn's API](#understanding-scikit-learns-api-ğŸ§©)
    - [ğŸ”„ The Estimator API](#the-estimator-api-ğŸ”„)
    - [ğŸ“ˆ Fit and Predict Methods](#fit-and-predict-methods-ğŸ“ˆ)
    - [ğŸ”„ Pipelines](#pipelines-ğŸ”„)
5. [ğŸ“Š Basic Data Preprocessing](#basic-data-preprocessing-ğŸ“Š)
    - [ğŸ§¹ Handling Missing Values](#handling-missing-values-ğŸ§¹)
    - [ğŸ”¡ Encoding Categorical Variables](#encoding-categorical-variables-ğŸ”¡)
    - [ğŸ“ Feature Scaling](#feature-scaling-ğŸ“)
6. [ğŸ¤– Building Your First Model](#building-your-first-model-ğŸ¤–)
    - [ğŸ“š Loading a Dataset](#loading-a-dataset-ğŸ“š)
    - [ğŸ› ï¸ Splitting the Data](#splitting-the-data-ğŸ› ï¸)
    - [ğŸ“ˆ Training a Simple Classifier](#training-a-simple-classifier-ğŸ“ˆ)
    - [ğŸ“‰ Making Predictions](#making-predictions-ğŸ“‰)
7. [ğŸ“ˆ Model Evaluation Metrics](#model-evaluation-metrics-ğŸ“ˆ)
    - [âœ… Accuracy](#accuracy-âœ…)
    - [ğŸ“ Precision, Recall, and F1-Score](#precision-recall-and-f1-score-ğŸ“)
    - [ğŸ” Confusion Matrix](#confusion-matrix-ğŸ”)
8. [ğŸ› ï¸ğŸ“ˆ Example Project: Iris Classification](#example-project-iris-classification-ğŸ› ï¸ğŸ“ˆ)
9. [ğŸš€ğŸ“ Conclusion and Next Steps](#conclusion-and-next-steps-ğŸš€ğŸ“)
10. [ğŸ“œ Summary of Day 1 ğŸ“œ](#summary-of-day-1-ğŸ“œ)

---

## 1. ğŸŒŸ Welcome to Day 1

Welcome to **Day 1** of your 90-day journey to becoming a Scikit-Learn boss! Today, we'll lay the foundation by introducing Scikit-Learn, setting up your development environment, understanding its core API, performing basic data preprocessing, building your first machine learning model, and evaluating its performance.

---

## 2. ğŸ” What is Scikit-Learn? ğŸ”

**Scikit-Learn** is one of the most popular open-source machine learning libraries for Python. It provides simple and efficient tools for data mining and data analysis, built on top of NumPy, SciPy, and Matplotlib.

**Key Features:**

- **Wide Range of Algorithms**: Classification, regression, clustering, dimensionality reduction, and more.
- **Consistent API**: Makes it easy to switch between different models.
- **Integration with Other Libraries**: Works seamlessly with pandas, NumPy, and Matplotlib.
- **Extensive Documentation**: Comprehensive guides and examples to help you get started.

---

## 3. ğŸ› ï¸ Setting Up Your Environment ğŸ› ï¸

Before diving into Scikit-Learn, ensure your development environment is properly set up.

### ğŸ“¦ Installing Scikit-Learn ğŸ“¦

You can install Scikit-Learn using `pip` or `conda`.

**Using pip:**
```bash
pip install scikit-learn
```

**Using conda:**
```bash
conda install scikit-learn
```

### ğŸ’» Setting Up a Virtual Environment ğŸ’»

Creating a virtual environment helps manage dependencies and keep your projects organized.

**Using `venv`:**
```bash
# Create a virtual environment named 'env'
python -m venv env

# Activate the virtual environment
# On Windows:
env\Scripts\activate

# On macOS/Linux:
source env/bin/activate
```

**Using `conda`:**
```bash
# Create a conda environment named 'ml_env'
conda create -n ml_env python=3.8

# Activate the environment
conda activate ml_env
```

---

## 4. ğŸ§© Understanding Scikit-Learn's API ğŸ§©

Scikit-Learn follows a consistent and intuitive API design, making it easy to implement various machine learning algorithms.

### ğŸ”„ The Estimator API ğŸ”„

In Scikit-Learn, most objects follow the **Estimator API**, which includes:

- **Estimator**: An object that learns from data (`fit` method).
- **Predictor**: An object that makes predictions (`predict` method).

### ğŸ“ˆ Fit and Predict Methods ğŸ“ˆ

- **`fit(X, y)`**: Trains the model on the data.
- **`predict(X)`**: Makes predictions based on the trained model.

### ğŸ”„ Pipelines ğŸ”„

**Pipelines** allow you to chain multiple processing steps, ensuring that all steps are applied consistently during training and prediction.

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

# Create a pipeline with scaling and logistic regression
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', LogisticRegression())
])

# Train the pipeline
pipeline.fit(X_train, y_train)

# Make predictions
predictions = pipeline.predict(X_test)
```

---

## 5. ğŸ“Š Basic Data Preprocessing ğŸ“Š

Data preprocessing is essential to prepare your data for machine learning models.

### ğŸ§¹ Handling Missing Values ğŸ§¹

Missing values can adversely affect model performance. Scikit-Learn provides tools to handle them.

```python
from sklearn.impute import SimpleImputer
import pandas as pd

# Sample DataFrame
data = {
    'Age': [25, None, 35, 40],
    'Salary': [50000, 60000, None, 80000]
}
df = pd.DataFrame(data)

# Impute missing values with mean
imputer = SimpleImputer(strategy='mean')
df[['Age', 'Salary']] = imputer.fit_transform(df[['Age', 'Salary']])
print(df)
```

### ğŸ”¡ Encoding Categorical Variables ğŸ”¡

Machine learning models require numerical input. Convert categorical variables using encoding techniques.

```python
from sklearn.preprocessing import OneHotEncoder

# Sample DataFrame
data = {
    'City': ['New York', 'Los Angeles', 'Chicago', 'New York']
}
df = pd.DataFrame(data)

# One-Hot Encoding
encoder = OneHotEncoder(sparse=False)
encoded = encoder.fit_transform(df[['City']])
encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(['City']))
df = pd.concat([df, encoded_df], axis=1)
print(df)
```

### ğŸ“ Feature Scaling ğŸ“

Scaling features ensures that all variables contribute equally to the result.

```python
from sklearn.preprocessing import StandardScaler

# Sample DataFrame
data = {
    'Height': [150, 160, 170, 180, 190],
    'Weight': [50, 60, 70, 80, 90]
}
df = pd.DataFrame(data)

# Standardization
scaler = StandardScaler()
df[['Height_Scaled', 'Weight_Scaled']] = scaler.fit_transform(df[['Height', 'Weight']])
print(df)
```

---

## 6. ğŸ¤– Building Your First Model ğŸ¤–

Let's build a simple classification model using the Iris dataset.

### ğŸ“š Loading a Dataset ğŸ“š

Scikit-Learn provides easy access to common datasets.

```python
from sklearn.datasets import load_iris
import pandas as pd

# Load Iris dataset
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = pd.Series(iris.target, name='Species')
```

### ğŸ› ï¸ Splitting the Data ğŸ› ï¸

Divide the data into training and testing sets.

```python
from sklearn.model_selection import train_test_split

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### ğŸ“ˆ Training a Simple Classifier ğŸ“ˆ

We'll use a Logistic Regression classifier.

```python
from sklearn.linear_model import LogisticRegression

# Initialize the model
model = LogisticRegression(max_iter=200)

# Train the model
model.fit(X_train, y_train)
```

### ğŸ“‰ Making Predictions ğŸ“‰

Use the trained model to make predictions.

```python
# Make predictions
predictions = model.predict(X_test)
print(predictions)
```

---

## 7. ğŸ“ˆ Model Evaluation Metrics ğŸ“ˆ

Evaluate the performance of your model using various metrics.

### âœ… Accuracy âœ…

Measures the proportion of correct predictions.

```python
from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, predictions)
print(f"Accuracy: {accuracy * 100:.2f}%")
```

### ğŸ“ Precision, Recall, and F1-Score ğŸ“

Provide more insight into model performance, especially for imbalanced datasets.

```python
from sklearn.metrics import classification_report

report = classification_report(y_test, predictions, target_names=iris.target_names)
print(report)
```

### ğŸ” Confusion Matrix ğŸ”

Visualizes the performance of a classification model.

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, predictions)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()
```

---

## 8. ğŸ› ï¸ğŸ“ˆ Example Project: Iris Classification ğŸ› ï¸ğŸ“ˆ

Let's consolidate what you've learned by building a complete classification pipeline.

### ğŸ“‹ Project Overview

**Objective**: Develop a machine learning pipeline to classify Iris species based on flower measurements.

**Tools**: Python, Scikit-Learn, pandas, Matplotlib, Seaborn

### ğŸ“ Step-by-Step Guide

#### 1. Load and Explore the Dataset

```python
from sklearn.datasets import load_iris
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load Iris dataset
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = pd.Series(iris.target, name='Species')

# Combine features and target
df = pd.concat([X, y], axis=1)
print(df.head())

# Visualize pairplot
sns.pairplot(df, hue='Species', palette='Set1')
plt.show()
```

#### 2. Data Preprocessing

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

#### 3. Building and Training the Model

```python
from sklearn.linear_model import LogisticRegression

# Initialize and train the model
model = LogisticRegression(max_iter=200)
model.fit(X_train_scaled, y_train)
```

#### 4. Making Predictions and Evaluating the Model

```python
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Predictions
predictions = model.predict(X_test_scaled)

# Evaluation
print("Classification Report:")
print(classification_report(y_test, predictions, target_names=iris.target_names))

# Confusion Matrix
cm = confusion_matrix(y_test, predictions)
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()
```

---

## 9. ğŸš€ğŸ“ Conclusion and Next Steps ğŸš€ğŸ“

Congratulations on completing **Day 1** of "Becoming a Scikit-Learn Boss in 90 Days"! Today, you laid the groundwork by understanding what Scikit-Learn is, setting up your environment, navigating its API, performing basic data preprocessing, building your first machine learning model, and evaluating its performance.

### ğŸ”® Whatâ€™s Next?

- **Day 2: Supervised Learning â€“ Classification Algorithms**: Dive deeper into various classification algorithms like Decision Trees, K-Nearest Neighbors, and Support Vector Machines.
- **Day 3: Supervised Learning â€“ Regression Algorithms**: Explore regression techniques including Linear Regression, Ridge, Lasso, and Elastic Net.
- **Day 4: Model Evaluation and Selection**: Learn about cross-validation, hyperparameter tuning, and model selection strategies.
- **Day 5: Unsupervised Learning â€“ Clustering and Dimensionality Reduction**: Understand clustering algorithms like K-Means and techniques like PCA.
- **Day 6: Advanced Feature Engineering**: Master techniques to create and select features that enhance model performance.
- **Day 7: Ensemble Methods**: Explore ensemble techniques like Bagging, Boosting, and Stacking.
- **Day 8: Model Deployment with Scikit-Learn**: Learn how to deploy your models into production environments.
- **Days 9-90: Specialized Topics and Projects**: Engage in specialized topics and comprehensive projects to solidify your expertise.

### ğŸ“ Tips for Success

- **Practice Regularly**: Apply the concepts through exercises and real-world projects.
- **Engage with the Community**: Join forums, attend webinars, and collaborate with peers.
- **Stay Curious**: Continuously explore new features and updates in Scikit-Learn.
- **Document Your Work**: Keep a detailed journal of your learning progress and projects.

Keep up the great work, and stay motivated as you continue your journey to mastering Scikit-Learn and machine learning! ğŸš€ğŸ“š

---

<div style="text-align: left;">
  <p>âœ¨ Keep Learning, Keep Growing! âœ¨</p>
  <p>ğŸš€ Your Data Science Journey Continues ğŸš€</p>
  <p>ğŸ“š Happy Coding! ğŸ‰</p>
</div>

---

# ğŸ“œ Summary of Day 1 ğŸ“œ

- **ğŸ” What is Scikit-Learn?**: Introduced Scikit-Learn as a powerful machine learning library in Python.
- **ğŸ› ï¸ Setting Up Your Environment**: Installed Scikit-Learn and set up a virtual environment for project management.
- **ğŸ§© Understanding Scikit-Learn's API**: Explored the Estimator API, fit and predict methods, and the use of pipelines.
- **ğŸ“Š Basic Data Preprocessing**: Learned how to handle missing values, encode categorical variables, and scale features.
- **ğŸ¤– Building Your First Model**: Developed a simple Logistic Regression classifier using the Iris dataset.
- **ğŸ“ˆ Model Evaluation Metrics**: Evaluated the model using accuracy, precision, recall, F1-score, and confusion matrix.
- **ğŸ› ï¸ğŸ“ˆ Example Project: Iris Classification**: Completed a full machine learning pipeline from data loading to model evaluation.

